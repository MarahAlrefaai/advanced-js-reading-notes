The Code is designed to inspire and guide the ethical conduct of all computing professionals, including current and aspiring practitioners, instructors, students, influencers, and anyone who uses computing technology in an impactful way. Additionally, the Code serves as a basis for remediation when violations occur. The Code includes principles formulated as statements of responsibility, based on the understanding that the public good is always the primary consideration. Each principle is supplemented by guidelines, which provide explanations to assist computing professionals in understanding and applying the principle.1.1 Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing.

1.2 Avoid harm.

1.3 Be honest and trustworthy.

1.4 Be fair and take action not to discriminate.

1.5 Respect the work required to produce new ideas, inventions, creative works, and computing artifacts.



Software engineers shall commit themselves to making the analysis, specification, design, development, testing and maintenance of software a beneficial and respected profession. In accordance with their commitment to the health, safety and welfare of the public, software engineers shall adhere to the following Eight Principles:

1. PUBLIC – Software engineers shall act consistently with the public interest.

2. CLIENT AND EMPLOYER – Software engineers shall act in a manner that is in the best interests of their client and employer consistent with the public interest.

3. PRODUCT – Software engineers shall ensure that their products and related modifications meet the highest professional standards possible.

4. JUDGMENT – Software engineers shall maintain integrity and independence in their professional judgment.

5. MANAGEMENT – Software engineering managers and leaders shall subscribe to and promote an ethical approach to the management of software development and maintenance.

6. PROFESSION – Software engineers shall advance the integrity and reputation of the profession consistent with the public interest.

7. COLLEAGUES – Software engineers shall be fair to and supportive of their colleagues.

8. SELF – Software engineers shall participate in lifelong learning regarding the practice of their profession and shall promote an ethical approach to the practice of the profession.



While some people in the industry, like Tesla’s Elon Musk, believe fully autonomous vehicles could be on U.S. roads within a few years, others say it could be a decade or more — and even longer before the full promise of self-driving cars and trucks is realized.

The trolley problem is just one that has to be cracked before then.

There are others, like those faced by Daryn Nakhuda, the founder and CEO of Mighty AI, which is in the business of breaking down into data for self-driving cars all the objects they are going to need to “see” in order to predict and react. A bird flying at the window. A thrown ball. A mail truck parked so there is not enough space in the car’s lane to pass without crossing the center line.

Automakers will have to decide what the car “sees” and what it doesn’t. Seeing everything around it — and processing it — could be a waste of limited processing power. Which means another set of ethical and moral questions.

Then there is the question of how self-driving cars could be taught to learn and respond to the tasks they are given — the stuff of science fiction that seems about to come true. 

While self-driving cars can be programmed — told what to do when that school bus comes hurtling toward them  —- there are other options. Through millions of computer simulations and data from real self-driving cars being tested, the cars themselves can begin to learn the "best" way to respond to a given situation.

For example, Waymo — Google's self-driving car arm — in a recent government filing said through trial and error in simulations, it's teaching its cars how to navigate a tricky left turn against a flashing yellow arrow at a real intersection in Mesa, Ariz. The simulations — not the programmers — determine when it's best to inch into the intersection and when it's best to accelerate through it. And the cars learn how to mimic real driving.

Ultimately, through such testing, the cars themselves could potentially learn how best to get from Point A to Point B, just by having programmed them to discern what "best" means — say the fastest, safest, most direct route. Through simulation and data shared with real world conditions, the cars would "learn" and execute the request.


What’s in the Toolkit:
A checklist of 8 risk zones to help you identify the emerging areas of risk and social harm most critical for your team to start considering now.
14 scenarios to spark conversation and stretch your imagination about the long-term impacts of tech you’re building today.
7 future-proofing strategies to help you take ethical action today.